{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dscol\\OneDrive\\University of Chicago\\Courses\\CMSC 35401\\APS\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from ars import run_ars\n",
    "from aps import run_gaps\n",
    "import matplotlib.pyplot as plt\n",
    "from ars.ars_policy import ARSPolicy\n",
    "from aps.gaps_policy import GAPSPolicy\n",
    "from utils.normalizer import Normalizer\n",
    "from utils.hyperparameters import ARSHyperparameters, GAPSHyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HalfCheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(86)\n",
    "env = gym.make(\"HalfCheetah-v4\")\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "gaps_hp = GAPSHyperparameters(horizon=100)\n",
    "best_theta, value = run_gaps.train(env, gaps_policy, normalizer, gaps_hp, 86)\n",
    "trained_gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "trained_gaps_policy.theta = best_theta\n",
    "gaps_hp.horizon = 1000\n",
    "gaps_rewards = run_gaps.explore(env, gaps_hp, normalizer, trained_gaps_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(252.7307, dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521725467793333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0733,  0.2443,  0.1391, -0.3569, -0.0790, -0.1072,  0.2012,  0.1674,\n",
       "          0.4440,  0.4809, -0.4023,  0.3393,  0.1514, -0.1992,  0.4845,  0.3389,\n",
       "         -0.6538],\n",
       "        [-0.2314, -0.6901, -0.1915, -0.2033, -0.5623,  0.4544,  0.3754,  0.5267,\n",
       "          0.0014,  0.3156, -0.5000,  0.4193,  0.0299,  0.1043, -0.1974,  0.2040,\n",
       "         -0.0199],\n",
       "        [-0.1645,  0.3265,  0.1877, -0.3127,  0.1277, -0.4476, -0.4017, -0.1542,\n",
       "         -0.1563, -0.7305,  0.2373,  0.4193,  0.6381, -0.5194, -0.2807, -0.4424,\n",
       "          0.7059],\n",
       "        [ 0.4331, -0.2006, -0.1085,  0.6452, -0.3054, -0.6418, -0.5409, -0.1829,\n",
       "         -0.1726,  0.3741,  0.1381,  0.6336, -0.6157, -0.3658, -0.6940, -0.5740,\n",
       "         -0.6339],\n",
       "        [ 0.0376,  0.3130, -0.5793, -0.7275, -0.3568, -0.4957,  0.3524,  0.4955,\n",
       "          0.1699,  0.4040,  0.2424, -0.1380, -0.3075,  0.2326,  0.7303, -0.0900,\n",
       "         -0.5857],\n",
       "        [-0.4604, -0.1551, -0.6061,  0.4234,  0.4713, -0.4858,  0.6875, -0.2119,\n",
       "          0.7419, -0.2987, -0.5549, -0.5298,  0.4567, -0.4283,  0.0858, -0.1548,\n",
       "         -0.5196]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_policy.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"HalfCheetah-v4\")\n",
    "ars_hp = ARSHyperparameters(num_experiments=100, horizon=1000)\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "ars_policy = ARSPolicy(ars_hp, num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "trained_ars_policy = run_ars.train(env, ars_policy, normalizer, ars_hp)\n",
    "ars_hp.horizon = 1000\n",
    "ars_rewards = run_ars.explore(env, ars_hp, normalizer, trained_ars_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9787638137782251"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ars_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4017e-02,  1.5866e-03,  1.5272e-01,  8.5299e-03,  2.8107e-02,\n",
       "         -1.3827e-02, -1.8734e-02, -2.7089e-02, -6.8276e-03, -6.4990e-03,\n",
       "          3.1175e-02, -1.2990e-01, -3.4468e-02,  1.3881e-03,  2.7970e-04,\n",
       "          2.4618e-02, -1.6493e-02],\n",
       "        [-5.9352e-02,  1.6167e-02,  2.8351e-02,  1.2652e-01,  3.2480e-02,\n",
       "          6.3388e-03, -4.4591e-02, -9.6470e-03,  1.4744e-02,  2.4728e-02,\n",
       "          7.8527e-02, -1.0129e-01, -9.3935e-02, -1.5999e-02, -1.6527e-02,\n",
       "         -9.8344e-03, -4.9158e-03],\n",
       "        [-1.4011e-02,  2.8505e-02,  3.3690e-02,  2.1881e-02,  6.3391e-02,\n",
       "         -1.1072e-02,  6.2105e-03, -1.2291e-02,  1.5200e-04,  8.9602e-03,\n",
       "          1.6630e-02, -2.7426e-02, -2.5151e-03, -9.8881e-02, -8.4345e-03,\n",
       "         -1.3083e-03, -2.0212e-02],\n",
       "        [ 3.2953e-02, -4.5897e-02,  4.1744e-02, -3.9376e-03, -4.4351e-03,\n",
       "          2.4722e-01,  8.3002e-02,  6.3867e-02,  6.9407e-02,  2.8935e-02,\n",
       "          8.1658e-02,  4.4613e-03, -1.6986e-02, -1.5233e-02, -1.5371e-01,\n",
       "         -1.6229e-02,  1.0499e-02],\n",
       "        [ 5.4463e-02,  3.6178e-02,  6.1992e-02, -7.3210e-03,  3.9150e-03,\n",
       "         -1.9826e-02,  9.0194e-02,  1.6341e-02,  4.8429e-02, -4.3080e-03,\n",
       "          5.6296e-02,  4.0708e-03,  6.2849e-02,  4.4276e-03, -4.6572e-02,\n",
       "         -1.5630e-01,  2.8993e-02],\n",
       "        [ 1.0607e-02, -2.2318e-03,  2.4185e-03,  1.7688e-03, -2.6642e-02,\n",
       "         -1.8874e-02,  8.2732e-03,  4.6737e-02,  5.0584e-03,  4.4452e-02,\n",
       "          5.9891e-03, -2.0740e-02,  4.1923e-02,  2.3335e-02, -3.1053e-03,\n",
       "         -2.4916e-02, -1.4219e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_ars_policy.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_gaps_policy.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swimmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(901)\n",
    "env = gym.make(\"Swimmer-v4\")\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "gaps_hp = GAPSHyperparameters(horizon=100)\n",
    "best_theta, value = run_gaps.train(env, gaps_policy, normalizer, gaps_hp, 901)\n",
    "trained_gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "trained_gaps_policy.theta = best_theta\n",
    "gaps_hp.horizon = 1000\n",
    "gaps_rewards = run_gaps.explore(env, gaps_hp, normalizer, trained_gaps_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21.6888, dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.799727082779267"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.4899e-01,  5.4792e-01,  7.3388e-01, -6.0059e-01,  7.1527e-01,\n",
       "          4.0162e-01,  2.0171e-01,  1.8961e-01],\n",
       "        [-1.6403e-01, -6.3306e-04,  3.2891e-01, -7.3769e-01, -2.2104e-01,\n",
       "         -5.7414e-01,  2.3472e-01, -3.5053e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_policy.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Swimmer-v4\")\n",
    "ars_hp = ARSHyperparameters(num_experiments=100, horizon=1000)\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "ars_policy = ARSPolicy(ars_hp, num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "trained_ars_policy = run_ars.train(env, ars_policy, normalizer, ars_hp)\n",
    "ars_hp.horizon = 1000\n",
    "ars_rewards = run_ars.explore(env, ars_hp, normalizer, trained_ars_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289.1240807944222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ars_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5314, -0.1543, -0.7112, -0.0268,  0.6317, -0.1740,  0.2212,  0.0774],\n",
       "        [-0.2993,  0.6722, -0.3582, -0.0017,  0.4822, -0.4887,  0.2931,  0.1983]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_ars_policy.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Walker2d-v4\")\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "gaps_hp = GAPSHyperparameters(horizon=1000)\n",
    "best_theta, value = run_gaps.train(env, gaps_policy, normalizer, gaps_hp, 814)\n",
    "trained_gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "trained_gaps_policy.theta = best_theta\n",
    "gaps_hp.horizon = 1000\n",
    "gaps_rewards = run_gaps.explore(env, gaps_hp, normalizer, trained_gaps_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2372, dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.544518055249603"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3195, -0.3125,  0.6673,  0.2735, -0.5980, -0.5722, -0.3178,  0.5003,\n",
       "          0.0084,  0.3402, -0.7244,  0.6966,  0.3774, -0.3684,  0.4272,  0.4656,\n",
       "          0.5978],\n",
       "        [ 0.6354,  0.2447, -0.1581,  0.0013, -0.5187,  0.7107, -0.6499,  0.6267,\n",
       "          0.6302, -0.1977, -0.7285,  0.5571,  0.0641,  0.3190,  0.7077,  0.3470,\n",
       "          0.6077],\n",
       "        [ 0.7326, -0.2104,  0.1909, -0.6148,  0.3515, -0.6083,  0.5401,  0.1866,\n",
       "         -0.4982, -0.2473, -0.4651, -0.2176,  0.1168,  0.2751,  0.1347, -0.1358,\n",
       "          0.2037],\n",
       "        [-0.3896, -0.5878,  0.3757, -0.4448, -0.2396, -0.5164,  0.2574, -0.6995,\n",
       "          0.5102,  0.3690,  0.4438, -0.7397,  0.5719,  0.2025,  0.1315, -0.4996,\n",
       "          0.1246],\n",
       "        [-0.1221, -0.6521,  0.1466, -0.5848, -0.6823,  0.2802, -0.1751,  0.6364,\n",
       "         -0.2164, -0.3381, -0.5126, -0.0839,  0.2769, -0.2581,  0.5296, -0.3387,\n",
       "         -0.1074],\n",
       "        [-0.2879, -0.4185,  0.6367,  0.6208,  0.5411,  0.5678,  0.0363, -0.1299,\n",
       "          0.1207,  0.1013, -0.4283,  0.0969, -0.6848,  0.2413, -0.7321, -0.2414,\n",
       "          0.2119]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaps_policy.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Walker2d-v4\")\n",
    "ars_hp = ARSHyperparameters(num_experiments=100, horizon=1000)\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "ars_policy = ARSPolicy(ars_hp, num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "trained_ars_policy = run_ars.train(env, ars_policy, normalizer, ars_hp)\n",
    "ars_hp.horizon = 1000\n",
    "ars_rewards = run_ars.explore(env, ars_hp, normalizer, trained_ars_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327.0631509830997"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ars_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0195,  0.0618, -0.0609,  0.0003,  0.1283,  0.0157,  0.0088,  0.0771,\n",
       "          0.1013,  0.0785,  0.0005, -0.0463,  0.0959, -0.0404, -0.0171, -0.0220,\n",
       "          0.0972],\n",
       "        [-0.0851,  0.0663,  0.0339,  0.0389,  0.0048,  0.0971,  0.0293,  0.2055,\n",
       "          0.0451,  0.0116,  0.0267,  0.0651, -0.1550,  0.0081,  0.0470,  0.0315,\n",
       "          0.1080],\n",
       "        [ 0.0659,  0.2574,  0.0724,  0.1414, -0.0158,  0.0595,  0.1999,  0.1365,\n",
       "          0.1626,  0.1237,  0.1126,  0.0839,  0.0379, -0.1628,  0.0279,  0.0419,\n",
       "         -0.0053],\n",
       "        [-0.0032,  0.0764,  0.0623,  0.0398,  0.0482,  0.0116,  0.0726,  0.0753,\n",
       "          0.1457,  0.0301,  0.0068,  0.0527,  0.0019,  0.0696, -0.0023,  0.1535,\n",
       "          0.0305],\n",
       "        [ 0.0039,  0.1329,  0.0394,  0.0452,  0.1301,  0.1362, -0.0312,  0.0930,\n",
       "          0.0575,  0.0620,  0.0808, -0.0017, -0.0004,  0.0246,  0.0708, -0.1561,\n",
       "          0.0863],\n",
       "        [-0.0342,  0.1269,  0.1853,  0.0833,  0.0694,  0.0813,  0.1003, -0.0171,\n",
       "          0.1276,  0.1509,  0.1399,  0.0720,  0.0801, -0.0056,  0.0615,  0.0467,\n",
       "         -0.2211]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_ars_policy.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 1\n",
      "Experiment: 2\n",
      "Experiment: 3\n",
      "Experiment: 4\n",
      "Experiment: 5\n",
      "Experiment: 6\n",
      "Experiment: 7\n",
      "Experiment: 8\n",
      "Experiment: 9\n",
      "Experiment: 10\n",
      "Experiment: 11\n",
      "Experiment: 12\n",
      "Experiment: 13\n",
      "Experiment: 14\n",
      "Experiment: 15\n",
      "Experiment: 16\n",
      "Experiment: 17\n",
      "Experiment: 18\n",
      "Experiment: 19\n",
      "Experiment: 20\n",
      "Experiment: 21\n",
      "Experiment: 22\n",
      "Experiment: 23\n",
      "Experiment: 24\n",
      "Experiment: 25\n",
      "Experiment: 26\n",
      "Experiment: 27\n",
      "Experiment: 28\n",
      "Experiment: 29\n",
      "Experiment: 30\n",
      "Experiment: 31\n",
      "Experiment: 32\n",
      "Experiment: 33\n",
      "Experiment: 34\n",
      "Experiment: 35\n",
      "Experiment: 36\n",
      "Experiment: 37\n",
      "Experiment: 38\n",
      "Experiment: 39\n",
      "Experiment: 40\n",
      "Experiment: 41\n",
      "Experiment: 42\n",
      "Experiment: 43\n",
      "Experiment: 44\n",
      "Experiment: 45\n",
      "Experiment: 46\n",
      "Experiment: 47\n",
      "Experiment: 48\n",
      "Experiment: 49\n",
      "Experiment: 50\n",
      "Experiment: 51\n",
      "Experiment: 52\n",
      "Experiment: 53\n",
      "Experiment: 54\n",
      "Experiment: 55\n",
      "Experiment: 56\n",
      "Experiment: 57\n",
      "Experiment: 58\n",
      "Experiment: 59\n",
      "Experiment: 60\n",
      "Experiment: 61\n",
      "Experiment: 62\n",
      "Experiment: 63\n",
      "Experiment: 64\n",
      "Experiment: 65\n",
      "Experiment: 66\n",
      "Experiment: 67\n",
      "Experiment: 68\n",
      "Experiment: 69\n",
      "Experiment: 70\n",
      "Experiment: 71\n",
      "Experiment: 72\n",
      "Experiment: 73\n",
      "Experiment: 74\n",
      "Experiment: 75\n",
      "Experiment: 76\n",
      "Experiment: 77\n",
      "Experiment: 78\n",
      "Experiment: 79\n",
      "Experiment: 80\n",
      "Experiment: 81\n",
      "Experiment: 82\n",
      "Experiment: 83\n",
      "Experiment: 84\n",
      "Experiment: 85\n",
      "Experiment: 86\n",
      "Experiment: 87\n",
      "Experiment: 88\n",
      "Experiment: 89\n",
      "Experiment: 90\n",
      "Experiment: 91\n",
      "Experiment: 92\n",
      "Experiment: 93\n",
      "Experiment: 94\n",
      "Experiment: 95\n",
      "Experiment: 96\n",
      "Experiment: 97\n",
      "Experiment: 98\n",
      "Experiment: 99\n",
      "Experiment: 100\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Hopper-v4\")\n",
    "num_inputs = env.observation_space.shape[0]\n",
    "num_outputs = env.action_space.shape[0]\n",
    "gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "normalizer = Normalizer(num_inputs)\n",
    "gaps_hp = GAPSHyperparameters(horizon=1000)\n",
    "best_theta, value = run_gaps.train(env, gaps_policy, normalizer, gaps_hp, 814)\n",
    "trained_gaps_policy = GAPSPolicy(num_inputs, num_outputs)\n",
    "trained_gaps_policy.theta = best_theta\n",
    "gaps_hp.horizon = 1000\n",
    "gaps_rewards = run_gaps.explore(env, gaps_hp, normalizer, trained_gaps_policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
